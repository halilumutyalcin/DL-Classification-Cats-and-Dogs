{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Numpy, Matplotlib, Tensorflow 2 and Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# NumPy - mathematical functions on multi-dimensional arrays and matrices\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib - plotting library to create graphs and charts\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow - end-to-end open source platform for machine learning.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras - high-level API for TensorFlow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# OS module for Python\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def showImages(arr):\n",
    "#     fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
    "#     axes = axes.flatten()\n",
    "#     for img, ax in zip(arr, axes):\n",
    "#         ax.imshow(img)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will use three data sets (images) of cats and dogs.\n",
    "\n",
    "- Train data set to train and fit our model.\n",
    "- Validation data set that we will be using during the training of the model to validate the effectiveness of the training.\n",
    "- Test data set that we will be using to test our model to see hw it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define where the images for training, validation and test are in our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './data/train'\n",
    "validate_dir = './data/validation'\n",
    "test_dir = './data/test'\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "validate_dogs_dir = os.path.join(validate_dir, 'dogs')\n",
    "validate_cats_dir = os.path.join(validate_dir, 'cats')\n",
    "test_cats_and_dogs_dir = os.path.join(test_dir, 'cats_and_dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the number of images in each directory that we will later use for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dogs_train = len(os.listdir(train_dogs_dir))\n",
    "num_cats_train = len(os.listdir(train_cats_dir))\n",
    "num_dogs_validate = len(os.listdir(validate_dogs_dir))\n",
    "num_cats_validate = len(os.listdir(validate_cats_dir))\n",
    "\n",
    "train_total = num_dogs_train + num_cats_train\n",
    "validate_total = num_dogs_validate + num_cats_validate\n",
    "test_total = len(os.listdir(test_cats_and_dogs_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the batch size which we will use for our ImageDataGenerator to define how many training examples are utilized in one iteration of training.\n",
    "\n",
    "We will also define the image size which defines the size of the image our ImageDataGenerator will generate for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_size = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will configure our ImageDataGenerator. ImageDataGenerator is Keras function data enables us data augmentation which means replacing the original batch of images with new and randomly transformed batch. This is useful and improves the training of our model because we can feed our model with new (augmented) images in each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define our ImageDataGenerator here only with rescale=1./255 that will standardize the numeric values in the matrix of our images.\n",
    "\n",
    "You cal also try the following options:\n",
    "- shear_range=0.2 - defines shear trainsformation intensity to our image\n",
    "- zoom_range=0.2 - defines the range of random zoom applied to ur images\n",
    "- horizontal_flip=True - randomly flips images horizontally.\n",
    "\n",
    "Feel free to experiment more by using the documentation of the function here: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "Remember that adding more options to the ImageDataGenerator adds complexity and therefore increases comsumption of the processing pwoer and the memory so experiment to find the right balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have defined general criteria for our image generator now we will define the flow of images for each data set train, validate and test using flow_from_directory function of ImageDataGenerator.\n",
    "\n",
    "Here are the configuration option we are using:\n",
    " - batch_size - how many training examples are utilized in one iteration of training\n",
    " - directory - where our images are\n",
    " - shuffle - whether to shuffle the images\n",
    " - target_size - the target size of our image that the function will return\n",
    " - class_mode - we are using \"binary\" because in our example we have two categories cats or dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 4800 images belonging to 2 classes.\n",
      "Found 200 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_img_gen = img_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                           directory=train_dir,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(img_size, img_size),\n",
    "                                           class_mode='binary')\n",
    "\n",
    "validate_img_gen = img_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                               directory=validate_dir,\n",
    "                                               shuffle=False,\n",
    "                                               target_size=(img_size, img_size),\n",
    "                                               class_mode='binary')\n",
    "\n",
    "test_img_gen = img_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                               directory=test_dir,\n",
    "                                               shuffle=False,\n",
    "                                               target_size=(img_size, img_size),\n",
    "                                               class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display some images generated from our train image generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showImages([train_img_gen[0][0][0] for i in range(15)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create our Neural Network for to distinguish images of cats and dogs.\n",
    "\n",
    "The model we are going to use for our networks is the sequential model which is suitable for most problems. It does not allow you to create models that share layers or have multiple inputs or outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then add to our model a few 2D convolution layers.\n",
    "\n",
    "We are explaining the meaning of the layers and parameters in the code but here are some of the most important elements:\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    " - 32 means the number of output filters in the convolution\n",
    " - (3, 3) is kernel size of the layer which specifies the height and width of the 2D convolution window. It usually depends on the size of the image\n",
    " - activation='relu' - defines the activation function on the output of the nodes of the layer. ReLU is the most commonly used activation function in neural networks. You can experiment and learn more about diffeernt activation functions on Keras documentation (https://keras.io/api/layers/activations/).\n",
    " - input_shape=(150, 150, 3) is the image size 150x150 with the three RGB colors\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " - Max pooling operation for 2D spatial data which is a downsampling strategy in Convolutional Neural Networks. It downsamples the input by taking the maximum value over the window defined by pool_size for each dimension.\n",
    " \n",
    "model.add(Flatten())\n",
    " - Flattens the input so we can introduce a standard Dense layer that will lead us to a single result layer. Before this operation we have three dimensional data of width, height, and color of each pixel of the image\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    " - regular densely-connected layer. Densely-connected means that each neuron in a layer receives an input from all the neurons in the previous layer.\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    " - The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time. This helps prevent overfitting.\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    " - is the last layer in the network which will return the probability of a cat or a dog as a number between 0-cat and 1-dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compile our netowrk with the loss function, optimizer function and we define the metrics as accuracy so we can see how the accuracy of our network is improving during the fitting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop', # rmsprop or adam\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now view the summary so we can see in details the structure of our neural network model including number and types of layers, total parameters, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,846,977\n",
      "Trainable params: 1,846,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start the model training process using the train_img_gen generator and also validating at each ste using validate_img_gen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "626/626 [==============================] - 1210s 2s/step - loss: 0.6438 - accuracy: 0.6274 - val_loss: 0.5164 - val_accuracy: 0.7470\n",
      "Epoch 2/5\n",
      "626/626 [==============================] - 1159s 2s/step - loss: 0.4909 - accuracy: 0.7664 - val_loss: 0.4545 - val_accuracy: 0.7892\n",
      "Epoch 3/5\n",
      "626/626 [==============================] - 1130s 2s/step - loss: 0.4025 - accuracy: 0.8225 - val_loss: 0.3625 - val_accuracy: 0.8354\n",
      "Epoch 4/5\n",
      "626/626 [==============================] - 1131s 2s/step - loss: 0.3429 - accuracy: 0.8529 - val_loss: 0.3830 - val_accuracy: 0.8226\n",
      "Epoch 5/5\n",
      "626/626 [==============================] - 1138s 2s/step - loss: 0.3076 - accuracy: 0.8726 - val_loss: 0.3221 - val_accuracy: 0.8686\n"
     ]
    }
   ],
   "source": [
    "fit_result = model.fit_generator(\n",
    "            train_img_gen,\n",
    "            steps_per_epoch=int(np.ceil(train_total / float(batch_size))),\n",
    "            epochs=5, \n",
    "            validation_data=validate_img_gen,\n",
    "            validation_steps=int(np.ceil(validate_total / float(batch_size)))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy improved significantly after each epoch achieving around 90% of accuracy at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6274461, 0.7664237, 0.82253397, 0.8529353, 0.87260383]\n"
     ]
    }
   ],
   "source": [
    "print(fit_result.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save our trained model so we can load it and use without the need for it to be trained again in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')\n",
    "# model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/6 [=================================] - 3s 421ms/step\n",
      "Accuracy on the test data: 90.0%\n"
     ]
    }
   ],
   "source": [
    "test_img_gen.reset()\n",
    "\n",
    "pred = model.predict_generator(test_img_gen, steps=test_total/batch_size, verbose=1)\n",
    "\n",
    "predicted_class_indices = np.round(pred)\n",
    "\n",
    "labels = (train_img_gen.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k[0]] for k in predicted_class_indices]\n",
    "\n",
    "filenames = test_img_gen.filenames\n",
    "results = pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for index, value in results.iterrows():\n",
    "    filename = value[0].replace('cats_and_dogs/', '')\n",
    "    prediction_value = value[1]\n",
    "    if (filename.split('.')[0] + 's' == prediction_value):\n",
    "        correct = correct + 1\n",
    "    else:\n",
    "        incorrect = incorrect + 1\n",
    "\n",
    "print('Accuracy on the test data: ' + str(round((correct/test_total)*100, 1)) + '%')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
